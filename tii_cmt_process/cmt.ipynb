{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xóa hết bình luận rỗng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('total_comment(13-4-2022).json')\n",
    "print(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bình luận theo số sao\n",
    "r0 = df[df['rate'] == 0]\n",
    "r1 = df[df['rate'] == 1]\n",
    "r2 = df[df['rate'] == 2]\n",
    "r3 = df[df['rate'] == 3]\n",
    "r4 = df[df['rate'] == 4]\n",
    "r5 = df[df['rate'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bình luận rỗng theo số sao\n",
    "r0_empty = r0[r0['content'] == '']\n",
    "r1_empty = r1[r1['content'] == '']\n",
    "r2_empty = r2[r2['content'] == '']\n",
    "r3_empty = r3[r3['content'] == '']\n",
    "r4_empty = r4[r4['content'] == '']\n",
    "r5_empty = r5[r5['content'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tổng bình luận rỗng\n",
    "print('số bl rỗng 0s',len(r0_empty))\n",
    "print('số bl rỗng 1s',len(r1_empty))\n",
    "print('số bl rỗng 2s',len(r2_empty))\n",
    "print('số bl rỗng 3s',len(r3_empty))\n",
    "print('số bl rỗng 4s',len(r4_empty))\n",
    "print('số bl rỗng 5s',len(r5_empty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa tất cả bl rỗng\n",
    "df = df.drop(r0_empty.index)\n",
    "df = df.drop(r1_empty.index)\n",
    "df = df.drop(r2_empty.index)\n",
    "df = df.drop(r3_empty.index)\n",
    "df = df.drop(r4_empty.index)\n",
    "df = df.drop(r5_empty.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger # thư viện NLP tiếng Việt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim # thư viện NLP\n",
    "import os\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import KeyedVectors\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df['content']\n",
    "y = df['rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa: thay thế từ viết tắt và xóa các từ dừng \n",
    "td = open('tu_dung', 'r', encoding='UTF-8').readlines()\n",
    "vt = open('viet_tat', 'r', encoding='UTF-8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển sang viết thường\n",
    "for e in X1:\n",
    "    e.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thay thế từ viết tắt\n",
    "def dong_nghia(self):\n",
    "    list_text = self.split(' ')\n",
    "    for i in range(len(list_text)):\n",
    "        for j in range(len(vt)):\n",
    "            if(list_text[i] == vt[j][0]):\n",
    "                list_text[i] = vt[j][1]\n",
    "    self = ' '.join(list_text)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tu_dung(self):\n",
    "    words = []\n",
    "    split_words = self.split()\n",
    "    for word in split_words:\n",
    "        if word not in td:\n",
    "            words.append(word)\n",
    "    return ' '.join(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa từ dừng \n",
    "X2 = []\n",
    "for e in X1:\n",
    "    X2.append(tu_dung(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = []\n",
    "for e in X2:\n",
    "    X3.append(dong_nghia(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa ký tự đặc biệt và tách từ\n",
    "X = []\n",
    "for e in X3:\n",
    "    lines = gensim.utils.simple_preprocess(e)\n",
    "    lines = ' '.join(lines)\n",
    "    lines = ViTokenizer.tokenize(lines)\n",
    "    X.append(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# File pickle chứa cmt đã đc xóa ký tự đb và tt\n",
    "# pickle.dump(X, open('X_data.pkl', 'wb'))\n",
    "# pickle.dump(y, open('y_data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = pd.read_pickle(r'X_data.pkl')\n",
    "y = pd.read_pickle(r'y_data.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[11]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# chia nhãn\n",
    "for index, item in enumerate(y):\n",
    "    switch(item){\n",
    "\tif item < 3:\n",
    "\t\ty[index] = 'neg'\n",
    "    elif item > 3:\n",
    "        y[index] = 'pos'\n",
    "    elif item == 3:\n",
    "        y[index] = 'neu'\n",
    "print(y[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 0 là tiêu cực 1 là tích cực\n",
    "arr = numpy.asarray(y)\n",
    "arr[ arr == 1 ] = 0\n",
    "arr[ arr == 2 ] = 0\n",
    "arr[ arr == 3 ] = 1\n",
    "arr[ arr == 4 ] = 1\n",
    "arr[ arr == 5 ] = 1\n",
    "print(arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#pickle.dump(y, open('y.pkl', 'wb'))\n",
    "y = pd.read_pickle(r'y.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập dữ liệu để kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# pickle.dump(X, open('X_train_count.pkl', 'wb'))\n",
    "# pickle.dump(y, open('X_test_count.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Xây dựng mô hình"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Phân loại văn bản với Naive Bayes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training Naive Bayes in 36.631016969680786 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# An n-gram is just a string of n words in a row\n",
    "# max_df loại những từ xuất hiện >80% tdl\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),\n",
    "                                             max_df=0.8,\n",
    "                                             max_features=None)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())\n",
    "                    ])\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "print('Done training Naive Bayes in', train_time, 'seconds.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Save model\n",
    "pickle.dump(text_clf, open('model/naive_bayes.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, Accuracy = 0.9214670418755474\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb_model = pd.read_pickle('model/naive_bayes.pkl')\n",
    "y_pred = nb_model.predict(X_test)\n",
    "print('Naive Bayes, Accuracy =', np.mean(y_pred == y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Phân loại văn bản với LogisticRegression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training Linear Classifier in 183.32998919487 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start_time = time.time()\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),\n",
    "                                             max_df=0.8,\n",
    "                                             max_features=None)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LogisticRegression(solver='lbfgs',\n",
    "                                                multi_class='auto',\n",
    "                                                max_iter=10000))\n",
    "                    ])\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "print('Done training Linear Classifier in', train_time, 'seconds.')\n",
    "\n",
    "# Save model\n",
    "pickle.dump(text_clf, open('model/linear_classifier.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Accuracy = 0.9400405591538487\n"
     ]
    }
   ],
   "source": [
    "lr_model = pd.read_pickle('model/linear_classifier.pkl')\n",
    "y_pred = lr_model.predict(X_test)\n",
    "print('SVM, Accuracy =', np.mean(y_pred == y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Phân loại văn bản với PhoBert"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Đánh giá mô hình phân loại cho văn bản"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "len(y_test)\n",
    "y_test = y_test.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "0\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Test thử mô hình naive bayes với tập test\n",
    "for i in range(0, 20):\n",
    "    test = nb_model.predict([X_test[i]])\n",
    "    print(test)\n",
    "    print(y_test[i])\n",
    "    print('---')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "test = 'không thích sản phẩm'\n",
    "test = nb_model.predict([X_test[i]])\n",
    "print(test)\n",
    "test = 'thích sản phẩm'\n",
    "test = nb_model.predict([X_test[i]])\n",
    "print(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "0\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[0]\n",
      "0\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n",
      "[0]\n",
      "0\n",
      "---\n",
      "[1]\n",
      "1\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Test thử mô hình hồi quy với tập test\n",
    "for i in range(20, 40):\n",
    "    test = lr_model.predict([X_test[i]])\n",
    "    print(test)\n",
    "    print(y_test[i])\n",
    "    print('---')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "test = 'không thích sản phẩm'\n",
    "test = lr_model.predict([X_test[i]])\n",
    "print(test)\n",
    "test = 'thích sản phẩm'\n",
    "print(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.26      0.39     57709\n",
      "           1       0.93      0.99      0.96    532540\n",
      "\n",
      "    accuracy                           0.92    590249\n",
      "   macro avg       0.87      0.63      0.68    590249\n",
      "weighted avg       0.91      0.92      0.90    590249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Naive_bayes\n",
    "\n",
    "nb_model = pd.read_pickle('model/naive_bayes.pkl')\n",
    "y_pred = nb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, labels=[0,1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "'cáp xuất hình thất_vọng'"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [X_test[211]]\n",
    "test = lr_model.predict(test)\n",
    "print(test)\n",
    "X_test[211]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.57      0.65     57709\n",
      "           1       0.95      0.98      0.97    532540\n",
      "\n",
      "    accuracy                           0.94    590249\n",
      "   macro avg       0.86      0.78      0.81    590249\n",
      "weighted avg       0.94      0.94      0.94    590249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# linear_classifier\n",
    "\n",
    "lr_model = pd.read_pickle('model/linear_classifier.pkl')\n",
    "y_pred = lr_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, labels=[0,1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}