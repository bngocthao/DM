{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xóa hết bình luận rỗng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('total_comment(13-4-2022).json')\n",
    "print(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bình luận theo số sao\n",
    "r0 = df[df['rate'] == 0]\n",
    "r1 = df[df['rate'] == 1]\n",
    "r2 = df[df['rate'] == 2]\n",
    "r3 = df[df['rate'] == 3]\n",
    "r4 = df[df['rate'] == 4]\n",
    "r5 = df[df['rate'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bình luận rỗng theo số sao\n",
    "r0_empty = r0[r0['content'] == '']\n",
    "r1_empty = r1[r1['content'] == '']\n",
    "r2_empty = r2[r2['content'] == '']\n",
    "r3_empty = r3[r3['content'] == '']\n",
    "r4_empty = r4[r4['content'] == '']\n",
    "r5_empty = r5[r5['content'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tổng bình luận rỗng\n",
    "print('số bl rỗng 0s',len(r0_empty))\n",
    "print('số bl rỗng 1s',len(r1_empty))\n",
    "print('số bl rỗng 2s',len(r2_empty))\n",
    "print('số bl rỗng 3s',len(r3_empty))\n",
    "print('số bl rỗng 4s',len(r4_empty))\n",
    "print('số bl rỗng 5s',len(r5_empty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa tất cả bl rỗng\n",
    "df = df.drop(r0_empty.index)\n",
    "df = df.drop(r1_empty.index)\n",
    "df = df.drop(r2_empty.index)\n",
    "df = df.drop(r3_empty.index)\n",
    "df = df.drop(r4_empty.index)\n",
    "df = df.drop(r5_empty.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger # thư viện NLP tiếng Việt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim # thư viện NLP\n",
    "import os\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import KeyedVectors \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df['content']\n",
    "y = df['rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa: thay thế từ viết tắt và xóa các từ dừng \n",
    "td = open('tu_dung', 'r', encoding='UTF-8').readlines()\n",
    "vt = open('viet_tat', 'r', encoding='UTF-8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển sang viết thường\n",
    "for e in X1:\n",
    "    e.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thay thế từ viết tắt\n",
    "def dong_nghia(self):\n",
    "    list_text = self.split(' ')\n",
    "    for i in range(len(list_text)):\n",
    "        for j in range(len(vt)):\n",
    "            if(list_text[i] == vt[j][0]):\n",
    "                list_text[i] = vt[j][1]\n",
    "    self = ' '.join(list_text)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tu_dung(self):\n",
    "    words = []\n",
    "    split_words = self.split()\n",
    "    for word in split_words:\n",
    "        if word not in td:\n",
    "            words.append(word)\n",
    "    return ' '.join(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa từ dừng \n",
    "X2 = []\n",
    "for e in X1:\n",
    "    X2.append(tu_dung(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = []\n",
    "for e in X2:\n",
    "    X3.append(dong_nghia(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa ký tự đặc biệt và tách từ\n",
    "X = []\n",
    "for e in X3:\n",
    "    lines = gensim.utils.simple_preprocess(e)\n",
    "    lines = ' '.join(lines)\n",
    "    lines = ViTokenizer.tokenize(lines)\n",
    "    X.append(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# File pickle chứa cmt đã đc xóa ký tự đb và tt\n",
    "pickle.dump(X, open('X_data.pkl', 'wb'))\n",
    "pickle.dump(y, open('y_data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập dữ liệu để kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer:Tạo 1 ma trận mà mỗi hàng sẽ đại diện cho một văn bản, mỗi cột đại diện cho \n",
    "# một từ có trong từ điển, và mỗi ô (cell) sẽ chứa tần suất xuất hiện của từ trong văn bản tương ứng.\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(X_train)\n",
    "\n",
    "# transform the training and validation train using count vectorizer object\n",
    "X_train_count = count_vect.transform(X_train)\n",
    "X_test_count = count_vect.transform(X_test)\n",
    "X_train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embeded\n",
    "from gensim.models import KeyedVectors \n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "word2vec_model_path = os.path.join(dir_path, \"tii_cmt_process/vi/vi.vec\")\n",
    "\n",
    "w2v = KeyedVectors.load_word2vec_format(word2vec_model_path)\n",
    "vocab = list(w2v.index_to_key)\n",
    "wv = w2v\n",
    "\n",
    "def get_word2vec_data(X):\n",
    "    word2vec_data = []\n",
    "    for x in X:\n",
    "        sentence = []\n",
    "        for word in x.split(\" \"):\n",
    "            if word in vocab:\n",
    "                sentence.append(wv[word])\n",
    "\n",
    "        word2vec_data.append(sentence)\n",
    "\n",
    "    return word2vec_data\n",
    "\n",
    "X_data_w2v = get_word2vec_data(X)\n",
    "X_test_w2v = get_word2vec_data(X_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
